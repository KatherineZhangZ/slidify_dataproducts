library(manipulate)
}
myHist <- function(mu){
mse <- mean(w(z - mu)^2)
g <- ggplot(galton, aes(x = child)) + geom_histogram(fill = "salmon", colour = "black", binwidth=1)
g <- g + geom_vline(xintercept = mu, size = 3)
g <- g + ggtitle(paste("mu = ", mu, ", MSE = ", round(mse, 2), sep = ""))
g
}
manipulate(myHist(mu),mu=slider(0.0001,3,step=0.01))
library(manipulate)
myHist <- function(mu){
mse <- mean(w*(z - mu)^2)
g <- ggplot(galton, aes(x = child)) + geom_histogram(fill = "salmon", colour = "black", binwidth=1)
g <- g + geom_vline(xintercept = mu, size = 3)
g <- g + ggtitle(paste("mu = ", mu, ", MSE = ", round(mse, 2), sep = ""))
g
}
manipulate(myHist(mu),mu=slider(0.0001,3,step=0.01))
manipulate(myHist(mu),mu=slider(0.0025,3,step=0.01))
library(manipulate)
myHist <- function(mu){
mse <- mean(w*(z - mu)^2)
g <- ggplot(galton, aes(x = z)) + geom_histogram(fill = "salmon", colour = "black", binwidth=1)
g <- g + geom_vline(xintercept = mu, size = 3)
g <- g + ggtitle(paste("mu = ", mu, ", MSE = ", round(mse, 2), sep = ""))
g
}
manipulate(myHist(mu),mu=slider(0.0025,3,step=0.01))
z
w
x-0.3
x
z
z-0.3
(z-0.3)^2
z2<-(z-0.3)^2
z2*w
sum(z2*w)
z2<-(z-1.077)^2
sum(z2*w)
z2<-(z-0.0025)^2
sum(z2*w)
z2<-(z-0.1471)^2
sum(z2*w)
x<-c(0.61,0.93,0.83,0.35,0.5,4,0.16,0.91,0.62,0.62)
y<-c(0.67,0.84,0.6,0.18,0.85,0.47,1.1,0.65,0.36)
lm(y~x)
lm(y ~ x)
x<-c(0.61,0.93,0.83,0.35,0.54,0.16,0.91,0.62,0.62)
lm(y ~ x)
m<-lm(y ~ x)
m
anova(m)
coef(m)
sumary(m)
summary(m)
resid(m)
data(mtcars)
mtcars
car <- lm(mpg ~ wt)
car <- lm(mpg ~ wt,data=mtcars)
coef(car)
avg(wt,data=mtcars)
avg(mtcars$wt)
average(mtcars$wt)
mean(mtcars$wt)
pred<-mean(mtcars$wt)
predict(car,newdata=pred)
pred<-data.frame(wt=mean(mtcars$wt))
predict(car,newdata=pred)
help(mtcars)
pred<-data.frame(wt=3)
predict(car,newdata=pred)
pred<-data.frame(wt=2)
predict(car,newdata=pred)
coef(car)
summary(car)
anova(cars)
anova(car)
rsid(car)
resid(m)
residual<-resid(m)
sum(residual)
data(mtcars)
head(mtcars)
factor(mtcars$cyl)
fcyl<-factor(mtcars$cyl)
lm(mtcars$mpg~fcyl mtcars$mpg)
lm(mtcars$mpg ~ fcyl,mtcars$mpg)
lm(mtcars$mpg ~ fcyl)
lm(mtcars$mpg ~ fcyl+mtcars$mpg)
lm(mtcars$mpg ~ fcyl+mtcars$wt)
lm(mtcars$mpg ~ fcyl)
interaction<-fcyl*mtcars$mpg
lm(mtcars$mpg ~ fcyl+mtcars$wt+fcyl*mtcars$wt)
result<-lm(mtcars$mpg ~ fcyl+mtcars$wt+fcyl*mtcars$wt)
summary(result)
result1<-lm(mtcars$mpg ~ fcyl+mtcars$wt)
summary(result1)
result<-lm(mtcars$mpg ~ fcyl+mtcars$wt+fcyl*mtcars$wt)
result<-lm(mtcars$mpg ~ fcyl+mtcars$wt+fcyl*mtcars$wt)
x<-x(0.586,0.166,-0.042,-0.614,11.72)
x<-c(0.586,0.166,-0.042,-0.614,11.72)
y<-c(0.549,-0.026,-0.127,-0.751,1.344)
lm(y~x)
?rexp
lamdsa<-0.2
sample<-40
n<-1000
hist(rexp(n))
# 1. A simulatin excercise
# 1. Show the sample mean and compare it to the theoretical mean of the distribution.
lamdsa<-0.2
sample<-40
n<-1000
hist(rexp(n))
mns=NULL
for (i in 1:1000) mns=c(mns,mean(rexp(40)))
hist(mns)
?rexp
lambda<-0.2
sample<-40
n<-1000
hist(rexp(sample))
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns)
?hist
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns col=red nclass=10)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns, col=red ,nclass=10)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns, col=red)
hist(mns)
mns
mns=NULL
lambda<-0.2
sample<-40
n<-1000
hist(rexp(sample))
set.seed(12345)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,break=20)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=20)
set.seed(12345)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=10)
set.seed(12345)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=20)
set.seed(12345)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=20)
set.seed(12345)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=50)
set.seed(12345)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=20)
set.seed(12345)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=30)
set.seed(1508)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=30)
set.seed(1508)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=30)
set.seed(1508)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=20)
set.seed(1508)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=10)
set.seed(1508)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=20)
?abline
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=20,col="blue")
abline(v=1/lambda,col="red")
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=20,col="lightblue")
abline(v=1/lambda,col="red")
?abline
# 1. A simulatin excercise
# 1. Show the sample mean and compare it to the theoretical mean of the distribution.
lambda<-0.2
sample<-40
n<-1000
hist(rexp(sample))
set.seed(1508)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=20,col="lightblue")
abline(v=1/lambda,col="red")
# 1. A simulatin excercise
# 1. Show the sample mean and compare it to the theoretical mean of the distribution.
lambda<-0.2
sample<-40
n<-1000
hist(rexp(sample))
set.seed(1508)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=20,col="lightblue")
#simulation mean
sim_mean=mean(mns)
#theory mean
theory_mean=1/lambda
abline(v=theory_mean,col="red")
abline(v=sim_mean,col="blue")
# 1. A simulatin excercise
# 1. Show the sample mean and compare it to the theoretical mean of the distribution.
lambda<-0.2
sample<-40
n<-1000
hist(rexp(sample))
set.seed(1508)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=20,col="lightblue")
#simulation mean
mean(mns)
#theory mean
1/lambda
abline(v=mean(mns),col="red")
abline(v=1/lambda,col="blue")
var(mns)
(1/lambda)^2/sample
qqnorm(mns)
qqnorm(mns)
qqline(mns)
hist(mns,breaks=20,col="lightblue")
lines(density(mns))
hist(mns,breaks=20,col="lightblue")
lines(density(mns))
hist(mns,breaks=20,col="lightblue")
lines(density(mns))
abline(v=mean(mns),col="red")
abline(v=1/lambda,col="blue")
hist(mns,breaks=20,col="lightblue",prob=TRUE)
abline(v=mean(mns),col="red")
abline(v=1/lambda,col="blue")
x<-seq(min(mns),max(mns))
y<-dnorm(x,mean=1/lambda,sd=((1/lambda)/sqrt(sample)))
lines(x,y)
hist(mns,breaks=20,col="lightblue",prob=TRUE)
abline(v=mean(mns),col="red")
abline(v=1/lambda,col="blue")
x<-seq(min(mns),max(mns),0.1)
y<-dnorm(x,mean=1/lambda,sd=((1/lambda)/sqrt(sample)))
lines(x,y)
# 1. A simulatin excercise
# 1. Show the sample mean and compare it to the theoretical mean of the distribution.
lambda<-0.2
sample<-40
n<-1000
hist(rexp(sample))
set.seed(1508)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=20,col="lightblue")
#simulation mean
mean(mns)
#theory mean
1/lambda
abline(v=mean(mns),col="red")
abline(v=1/lambda,col="blue")
# 2. Show how variable the sample is (via variance) and compare it to the theoretical variance of the distribution.
var(mns)
(1/lambda)^2/sample
# 3. Show that the distribution is approximately normal.
hist(mns,breaks=20,col="lightblue",prob=TRUE)
abline(v=mean(mns),col="red")
abline(v=1/lambda,col="blue")
x<-seq(min(mns),max(mns),0.1)
y<-dnorm(x,mean=1/lambda,sd=((1/lambda)/sqrt(sample)))
lines(x,y,lty=2,col="blue")
# 1. A simulatin excercise
# 1. Show the sample mean and compare it to the theoretical mean of the distribution.
lambda<-0.2
sample<-40
n<-1000
hist(rexp(sample))
set.seed(1508)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=20,col="lightblue")
#simulation mean
mean(mns)
#theory mean
1/lambda
abline(v=mean(mns),col="red")
abline(v=1/lambda,col="blue")
# 2. Show how variable the sample is (via variance) and compare it to the theoretical variance of the distribution.
var(mns)
(1/lambda)^2/sample
# 3. Show that the distribution is approximately normal.
hist(mns,breaks=20,col="lightblue",prob=TRUE)
abline(v=mean(mns),col="blue")
abline(v=1/lambda,col="red")
x<-seq(min(mns),max(mns),0.1)
y<-dnorm(x,mean=1/lambda,sd=((1/lambda)/sqrt(sample)))
lines(x,y,lty=2,col="red")
# 1. A simulatin excercise
# 1. Show the sample mean and compare it to the theoretical mean of the distribution.
lambda<-0.2
sample<-40
n<-1000
hist(rexp(sample))
set.seed(1508)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=20,col="lightblue")
#simulation mean
mean(mns)
#theory mean
1/lambda
abline(v=mean(mns),col="red")
abline(v=1/lambda,col="blue")
# 2. Show how variable the sample is (via variance) and compare it to the theoretical variance of the distribution.
var(mns)
(1/lambda)^2/sample
# 3. Show that the distribution is approximately normal.
hist(mns,breaks=20,col="lightblue",prob=TRUE)
abline(v=mean(mns),col="blue")
abline(v=1/lambda,col="red")
x<-seq(min(mns),max(mns),0.1)
y<-dnorm(x,mean=1/lambda,sd=((1/lambda)/sqrt(sample)))
lines(x,y,lty=2,col="red")
qqnorm(mns)
qqline(mns)
library(datasets)
data("ToothGrowth")
?ToothGrowth
ToothGrowth
## Part2
library(datasets)
data("ToothGrowth")
summary(ToothGrowth)
summary(ToothGrowth)
boxplot(len ~ supp*dose, data=ToothGrowth)
library(datasets)
data("ToothGrowth")
summary(ToothGrowth)
boxplot(len ~ supp*dose, data=ToothGrowth, xlab="combination of Supp and Dose", ylab="Length")
boxplot(len ~ supp data=ToothGrowth)
boxplot(len ~ dose data=ToothGrowth)
boxplot(len ~ supp, data=ToothGrowth)
boxplot(len ~ dose, data=ToothGrowth)
boxplot(len ~ supp, data=ToothGrowth)
boxplot(len ~ dose, data=ToothGrowth)
t.test(len ~ supp, paired=F,var.equal=F, data=ToothGrowth)
y<-dnorm(x,mean=1/lambda,sd=((1/lambda)/sqrt(sample)))
Title: Statistical Inference Course Project 1: Simulation Excercise
=========================================================
Overview
---------
This excercise conducted a exponential distribution simulation and compare the simulation result
with the Central limit Theorem. The comparision reveals that the mean and variance of the mean of 1000 simulation on 40 observations is almost identical to the theoretical mean and variance, and the distribution of the 1000 mean follows a approximately normal distribution.
Simulation
------------
The first step of the anlaysis is to create 1000 simulation of exponential distribution with 40 observations and lamda equals 0.2.
```{r}
lambda<-0.2
sample<-40
n<-1000
set.seed(1508)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
```
Q1.Show the sample mean and compare it to the theoretical mean of the distribution.
-------------
Sample mean is
```r{}
mean(mns)
```
Theory mean is 5
```r{}
1/lambda
```
The sample mean is almost identical as the theory mean.
```r{}
hist(mns,breaks=20,col="lightblue")
abline(v=mean(mns),col="red")
abline(v=1/lambda,col="blue")
```
Q2. Show how variable the sample is (via variance) and compare it to the theoretical variance of the distribution.
```r{}
var(mns)
(1/lambda)^2/sample
```
Q3. Show that the distribution is approximately normal.
```r{}
hist(mns,breaks=20,col="lightblue",prob=TRUE)
abline(v=mean(mns),col="blue")
abline(v=1/lambda,col="red")
x<-seq(min(mns),max(mns),0.1)
y<-dnorm(x,mean=1/lambda,sd=((1/lambda)/sqrt(sample)))
lines(x,y,lty=2,col="red")
qqnorm(mns)
qqline(mns)
```
Q3. Show that the distribution is approximately normal.
mns=NULL
# 1. A simulatin excercise
# 1. Show the sample mean and compare it to the theoretical mean of the distribution.
lambda<-0.2
sample<-40
n<-1000
hist(rexp(sample))
set.seed(1508)
mns=NULL
for (i in 1:n) mns=c(mns,mean(rexp(sample,rate=lambda)))
hist(mns,breaks=20,col="lightblue")
#simulation mean
mean(mns)
#theory mean
1/lambda
abline(v=mean(mns),col="red")
abline(v=1/lambda,col="blue")
# 2. Show how variable the sample is (via variance) and compare it to the theoretical variance of the distribution.
var(mns)
(1/lambda)^2/sample
# 3. Show that the distribution is approximately normal.
hist(mns,breaks=20,col="lightblue",prob=TRUE)
abline(v=mean(mns),col="blue")
abline(v=1/lambda,col="red")
x<-seq(min(mns),max(mns),0.1)
y<-dnorm(x,mean=1/lambda,sd=((1/lambda)/sqrt(sample)))
lines(x,y,lty=2,col="red")
qqnorm(mns)
qqline(mns)
?ToothGrowth
?t-test
?t.test
?boxplot
?mtcars
?aov
?step
boxplot(mpg ~ am, data=mtcars,xlab="0 = automatic 1 = manual")
system("pandoc -h")
?pandoc
library(knitr)
?pandoc
system("pandoc -h")
pandoc("tmp.Rmd", format="latex",ext="pdf")
install.packages(pandoc)
library(manipulate)
myplot<-function(s){}
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
}
library(manipulate)
install.packages(caret)
install.packages(pgmm)
shiny::runApp('Desktop/Coursera R/shiny_wine')
data(wine,package="rattle")
data(wine)
?wine
wine2M-wine[,-1]
wine2<-wine[,-1]
head(wine2)
getwd()
setwd("/Users/katherinezhang/Desktop/Coursera R/shiny_wine")
write.csv(wine2,"wine.csv")
runApp()
head(wine2)
wine2<-read.csv("./data/wine.csv")
wine2
runApp()
library(shinyapps)
shinyapps::deployApp('/Users/katherinezhang/Desktop/Coursera R/shiny_wine')
shinyapps::deployApp('/Users/katherinezhang/Desktop/Coursera R/shiny_wine')
head(wine)
install.packages("devtools")
install_github('slidify','ramnathv')
install_github('slidify','ramnathv')
library(devtools)
install_github('slidify','ramnathv')
install_github('slidifyLibraries','ramnathv')
library(slidify)
setwd("/Users/katherinezhang/Desktop/Coursera R/slidify_project")
author("dataproducts")
